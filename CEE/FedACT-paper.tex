\documentclass[a4paper,fleqn]{cas-dc}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{enumitem}
\usepackage{extarrows}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{pifont}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{float}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}

\def\tsc#1{\csdef{#1}{\textsc{\lowercase{#1}}\xspace}}
\tsc{WGM}
\tsc{QE}

\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}
\let\printorcid\relax

\shorttitle{FedACT: Byzantine-Resilient Federated Learning}    
\shortauthors{Li et al.}

\title[mode = title]{FedACT: A Byzantine-Resilient Federated Learning Framework with Autoencoder-Committee-TLBO for Heterogeneous Credit Scoring}  

\author[1,3]{Dengjia Li}
\author[1,3]{Chaoqun Ma}
\author[1,3]{Jinglan Yang}
\author[2,3]{Yuncheng Qiao}
\cormark[1]
\ead{qiaoyc@hnu.edu.cn}

\address[1]{Business School, Hunan University, Changsha 410082, China}
\address[2]{Business School, Shandong University of Technology, Zibo 255000, China}
\address[3]{Research Institute of Digital Society and Blockchain, Hunan University, China}
\cortext[1]{Corresponding author}

\begin{abstract}
Federated learning enables privacy-preserving collaborative credit scoring across financial institutions, yet its distributed architecture is vulnerable to Byzantine attacks where participants submit arbitrary model updates. This threat is amplified by data heterogeneity inherent in cross-silo consortia, which invalidates the clustering assumptions underlying existing defenses.

We propose FedACT, a three-stage Byzantine-resilient framework comprising: (1) an autoencoder-based anomaly detector with dual-metric scoring and MAD-based adaptive thresholding that partitions gradients into normal, uncertain, and anomalous zones; (2) a diversity-aware committee voting mechanism that resolves uncertain cases through consensus verification; and (3) TLBO-based robust aggregation coupled with reputation-driven incentives and Merkle-tree evidence chaining for auditability. Experiments on real-world credit datasets under twelve attack types and four heterogeneity scenarios demonstrate that FedACT maintains strong detection accuracy and model performance where existing defenses degrade.
\end{abstract}

\begin{keywords}
Federated learning \sep Byzantine resilience \sep Credit scoring \sep Anomaly detection \sep Data heterogeneity
\end{keywords}

\maketitle

%==============================================================================
% SECTION 1: INTRODUCTION
%==============================================================================
\section{Introduction}
\label{sec:intro}

Federated learning (FL) enables privacy-preserving collaborative model training across distributed data silos~\cite{McMahan:2017,Yang:2019:FL}. In credit scoring, financial institutions can jointly develop predictive models without sharing sensitive customer data, satisfying both regulatory compliance and commercial confidentiality requirements~\cite{Lessmann:2015,Voigt:2017}. However, the opacity inherent in FL---where the aggregation server cannot inspect local computations---creates a critical attack surface: \emph{Byzantine participants} may submit arbitrarily malicious model updates to poison the global model~\cite{Blanchard:2017,Lamport:1982}.

Byzantine attacks in federated credit scoring pose severe threats to model integrity. Adversaries may bias the model toward approving high-risk borrowers (fraudulent approval attacks), rejecting creditworthy applicants (legitimate rejection attacks), or systematically destabilizing the learning process (model degradation attacks). The heterogeneous nature of cross-silo financial data exacerbates this vulnerability: existing Byzantine-resilient aggregation methods~\cite{Blanchard:2017,Yin:2018,ElMhamdi:2018} assume that honest gradients cluster tightly around a common mean---an assumption violated when institutions serve distinct customer segments with varying default rates and feature distributions. Under such heterogeneity, strict detection thresholds incorrectly reject legitimate minority-institution updates, while lenient thresholds fail to identify sophisticated attacks designed to mimic benign statistical profiles~\cite{Karimireddy:2022}.

To address this fundamental tension between heterogeneity tolerance and attack detection, we propose \textbf{FedACT} (\textbf{Fed}erated \textbf{A}utoencoder-\textbf{C}ommittee-\textbf{T}LBO), a Byzantine defense framework that combines three complementary mechanisms:
\begin{enumerate}[leftmargin=*, nosep]
\item \textbf{Anomaly detection via learned manifolds.} An autoencoder learns the distribution of benign gradients and computes a dual-metric anomaly score combining reconstruction error with latent-space deviation. Adaptive MAD-based thresholding partitions gradients into normal, uncertain, and anomalous zones without requiring IID assumptions.
\item \textbf{Consensus verification for uncertain cases.} A diversity-constrained committee of verified participants adjudicates borderline gradients through majority voting, reducing both false positives from heterogeneity and false negatives from evasive attacks.
\item \textbf{Robust aggregation with accountability.} TLBO-based optimization aggregates verified gradients while a reputation mechanism creates long-term incentives for honest behavior. Merkle-tree evidence recording enables post-hoc auditability.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related work. Section~\ref{sec:preliminaries} formalizes the problem and threat model. Section~\ref{sec:method} presents FedACT. Section~\ref{sec:experiments} reports experimental evaluation. Section~\ref{sec:conclusion} concludes.


%==============================================================================
% SECTION 2: RELATED WORK
%==============================================================================
\section{Related Work}
\label{sec:related}

\textbf{Byzantine attacks in federated learning.} The Byzantine fault model, originating from distributed systems~\cite{Lamport:1982}, characterizes adversaries who submit arbitrary---potentially adversarially optimized---messages. In FL, Byzantine clients transmit malicious gradients to corrupt the global model~\cite{Blanchard:2017}. Attack strategies span a spectrum from naive perturbations (sign-flipping, noise injection, scaling) to defense-aware optimizations: ALIE~\cite{Baruch:2019} crafts updates within the tail of the benign distribution; IPM~\cite{Xie:2020} projects malicious directions onto the subspace spanned by honest updates; MinMax~\cite{Shejwalkar:2021} solves an optimization problem to maximally evade distance-based filters. Backdoor attacks~\cite{Bagdasaryan:2020,Wang:2020} embed hidden functionalities while preserving aggregate performance. The increasing sophistication of adaptive attacks motivates multi-stage defenses that combine detection, verification, and deterrence.

\textbf{Byzantine-resilient aggregation.} Defenses can be grouped into three paradigms. \emph{Robust statistics} methods apply coordinate-wise median, trimmed mean~\cite{Yin:2018}, or geometric median (RFA)~\cite{Pillutla:2019} to bound the influence of outliers. \emph{Distance-based selection} methods such as Krum, Multi-Krum~\cite{Blanchard:2017}, and Bulyan~\cite{ElMhamdi:2018} filter updates based on pairwise distances. \emph{Trust-anchored} methods like FLTrust~\cite{Cao:2021} reweight updates by similarity to a server-held reference gradient. A common limitation is the implicit IID assumption: honest gradients are expected to concentrate around a shared mean. Under non-IID data partitions typical of cross-silo credit scoring, this assumption fails, causing benign heterogeneous updates to be misclassified as malicious~\cite{Karimireddy:2022}.

\textbf{Learning-based anomaly detection.} Recent work applies anomaly detection models---isolation forests, autoencoders, clustering---to gradient-level features~\cite{Li:2023:AutoFL,Zhang:2022}. These approaches can capture complex distributional structure but typically lack (i) explicit mechanisms for borderline cases where detection confidence is low, and (ii) repeated-game incentive structures that deter strategic attackers over time.

\textbf{Positioning of FedACT.} Table~\ref{tab:comparison} contrasts existing methods with FedACT. Our framework addresses the heterogeneity-tolerance gap through learned manifold representations, introduces uncertainty-aware committee verification to handle borderline cases, and couples detection with reputation-based deterrence and auditable evidence recording.

\begin{table*}[!ht]
\centering
\caption{Capability comparison under heterogeneous, cross-silo credit scoring (\cmark: supported; $\sim$: partially/with prerequisite)}
\label{tab:comparison}
\small
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{3.2cm}cccc}
\toprule
\textbf{Method} & \textbf{Heterogeneity-tolerant} & \textbf{Uncertainty verification} & \textbf{No server data} & \textbf{Audit / deterrence} \\
\midrule
Krum / Multi-Krum~\cite{Blanchard:2017} & $\sim$ & \xmark & \cmark & \xmark \\
Bulyan~\cite{ElMhamdi:2018} & $\sim$ & \xmark & \cmark & \xmark \\
Median / TrimmedMean~\cite{Yin:2018} & $\sim$ & \xmark & \cmark & \xmark \\
RFA~\cite{Pillutla:2019} & $\sim$ & \xmark & \cmark & \xmark \\
FLTrust~\cite{Cao:2021} & $\sim$ & \xmark & $\sim$ & \xmark \\
Learning-based detectors~\cite{Li:2023:AutoFL,Zhang:2022} & $\sim$ & \xmark & \cmark & \xmark \\
\textbf{FedACT (Ours)} & \cmark & \cmark & \cmark & \cmark \\
\bottomrule
\end{tabular}%
}
\end{table*}


%==============================================================================
% SECTION 3: PRELIMINARIES
%==============================================================================
\section{Problem Formulation and Threat Model}
\label{sec:preliminaries}

\subsection{Federated Learning Formulation}

Consider $N$ clients (financial institutions) collaboratively training a global model $\mathbf{w} \in \mathbb{R}^d$. Client $i$ holds private dataset $\mathcal{D}_i = \{(\mathbf{x}_j, y_j)\}_{j=1}^{n_i}$ with local objective $F_i(\mathbf{w}) = \frac{1}{n_i} \sum_{j=1}^{n_i} \ell(f(\mathbf{w}; \mathbf{x}_j), y_j)$. The global objective is:
\begin{equation}
\min_{\mathbf{w}} F(\mathbf{w}) = \sum_{i=1}^{N} \frac{n_i}{n} F_i(\mathbf{w}), \quad n = \sum_{i=1}^{N} n_i
\label{eq:objective}
\end{equation}

Standard FedAvg~\cite{McMahan:2017} proceeds iteratively: at round $t$, the server broadcasts $\mathbf{w}^{(t)}$; each client computes local gradient $\mathbf{g}_i^{(t)} = \nabla F_i(\mathbf{w}^{(t)})$ and transmits it to the server; the server aggregates:
\begin{equation}
\mathbf{w}^{(t+1)} = \mathbf{w}^{(t)} - \eta \sum_{i=1}^{N} \frac{n_i}{n} \mathbf{g}_i^{(t)}
\label{eq:fedavg}
\end{equation}

\textbf{Data heterogeneity.} In cross-silo credit scoring, client data distributions $\mathcal{P}_i(\mathbf{x}, y)$ differ substantially due to customer segmentation, geographic factors, and institution-specific practices. This \emph{non-IID} setting induces high gradient variance: $\|\nabla F_i(\mathbf{w}) - \nabla F(\mathbf{w})\|$ can be large even for honest clients, complicating the distinction between heterogeneity and malicious behavior.

\subsection{Threat Model}

We consider $M < N/2$ Byzantine clients who may submit arbitrary gradients $\tilde{\mathbf{g}}_i$ to the server. The adversary has white-box knowledge of the model architecture and parameters, can adapt strategies across rounds, and may coordinate multiple compromised clients. Attack objectives include untargeted model degradation, targeted misclassification of specific borrower profiles, or backdoor injection.

We evaluate twelve attack types spanning three categories: \emph{basic attacks} (sign-flipping $\tilde{\mathbf{g}}_i = -\mathbf{g}_i$, Gaussian noise, scaling), \emph{sophisticated attacks} (ALIE~\cite{Baruch:2019}, IPM~\cite{Xie:2020}, MinMax~\cite{Shejwalkar:2021}), and \emph{other attacks} (label-flipping, backdoor~\cite{Bagdasaryan:2020}, free-riding, collusion).

The aggregation server is honest-but-curious: it executes the defense protocol correctly but may observe transmitted gradients. We assume secure channels, authenticated identities (no Sybil attacks), and honest majority ($M < N/2$).


%==============================================================================
% SECTION 4: METHODOLOGY
%==============================================================================
\section{The FedACT Framework}
\label{sec:method}

FedACT defends against Byzantine attacks through a three-stage pipeline illustrated in Figure~\ref{fig:framework}: (1) autoencoder-based anomaly detection that classifies gradients into normal, uncertain, and anomalous zones; (2) diversity-aware committee voting that resolves uncertain cases; and (3) TLBO-based robust aggregation with reputation updates and evidence recording.

\begin{figure*}[!ht]
\centering
\parbox{0.85\textwidth}{\centering\vspace{2.5cm}\textbf{[Framework Diagram]}\\\vspace{0.2cm}Gradients $\rightarrow$ Autoencoder Detection $\rightarrow$ Three-Zone Classification $\rightarrow$ Committee Voting $\rightarrow$ TLBO Aggregation $\rightarrow$ Model Update\vspace{2.5cm}}
\caption{FedACT architecture. Stage 1 computes anomaly scores via autoencoder reconstruction and latent deviation, partitioning gradients into $\mathcal{N}$ (normal), $\mathcal{U}$ (uncertain), $\mathcal{A}$ (anomalous). Stage 2 resolves $\mathcal{U}$ through diversity-constrained committee voting. Stage 3 aggregates verified gradients via TLBO optimization with reputation weighting.}
\label{fig:framework}
\end{figure*}

\subsection{Autoencoder-Based Anomaly Detection}

The detection stage learns a low-dimensional manifold of benign gradients and identifies attacks as off-manifold deviations. Let $\mathbf{g}_i \in \mathbb{R}^p$ denote client $i$'s gradient vector. An autoencoder with encoder $\phi_{\theta}: \mathbb{R}^p \to \mathbb{R}^k$ and decoder $\psi_{\theta}: \mathbb{R}^k \to \mathbb{R}^p$ is trained on historical gradients $\mathcal{G}_{\text{hist}}$ from verified normal clients to minimize reconstruction loss:
\begin{equation}
\mathcal{L}(\theta) = \frac{1}{|\mathcal{G}_{\text{hist}}|} \sum_{\mathbf{g} \in \mathcal{G}_{\text{hist}}} \|\psi_{\theta}(\phi_{\theta}(\mathbf{g})) - \mathbf{g}\|_2^2
\label{eq:ae_loss}
\end{equation}

For high-dimensional gradients ($p > 10{,}000$), we apply stratified layer-wise subsampling to bound memory and computation while preserving structural information. The latent dimension $k$ is set adaptively: $k=32$ for $p<5{,}000$, $k=64$ for $5{,}000 \le p \le 10{,}000$, and $k=128$ otherwise.

\textbf{Dual-metric anomaly score.} For each incoming gradient $\mathbf{g}_i$, we compute:
\begin{equation}
a_i = \lambda \cdot \frac{\|\mathbf{g}_i - \psi_{\theta}(\phi_{\theta}(\mathbf{g}_i))\|_2^2}{\max_j \|\mathbf{g}_j - \hat{\mathbf{g}}_j\|_2^2 + \epsilon} + (1-\lambda) \cdot \frac{\|\phi_{\theta}(\mathbf{g}_i) - \boldsymbol{\mu}_z\|_2}{\max_j \|\phi_{\theta}(\mathbf{g}_j) - \boldsymbol{\mu}_z\|_2 + \epsilon}
\label{eq:anomaly_score}
\end{equation}
where $\boldsymbol{\mu}_z = \frac{1}{|\mathcal{G}_{\text{hist}}|} \sum_{\mathbf{g} \in \mathcal{G}_{\text{hist}}} \phi_{\theta}(\mathbf{g})$ is the latent centroid, $\lambda = 0.7$ weights reconstruction error over latent deviation, and $\epsilon = 10^{-8}$ prevents division by zero. Max-normalization preserves relative magnitudes, which is critical for detecting scaling attacks.

\textbf{Adaptive thresholding.} We employ Median Absolute Deviation (MAD) for robust threshold estimation:
\begin{equation}
\tau = \text{med}(\mathbf{a}) + \kappa \cdot 1.4826 \cdot \text{MAD}(\mathbf{a}), \quad \text{MAD}(\mathbf{a}) = \text{med}(|a_i - \text{med}(\mathbf{a})|)
\label{eq:threshold}
\end{equation}
where $\kappa = 2.5$ controls sensitivity and $1.4826$ ensures consistency with Gaussian standard deviation. Gradients are partitioned into three zones:
\begin{equation}
\mathcal{N} = \{i: a_i < 0.7\tau\}, \quad \mathcal{U} = \{i: 0.7\tau \le a_i < 1.5\tau\}, \quad \mathcal{A} = \{i: a_i \ge 1.5\tau\}
\label{eq:zones}
\end{equation}
Gradients in $\mathcal{N}$ are accepted directly; those in $\mathcal{A}$ are rejected; those in $\mathcal{U}$ proceed to committee verification. This three-zone design accommodates heterogeneity by deferring borderline decisions rather than making binary choices under uncertainty.

\begin{algorithm}[!ht]
\caption{Autoencoder-Based Anomaly Detection}
\label{alg:autoencoder}
\small
\begin{algorithmic}[1]
\Require Gradients $\{\mathbf{g}_i\}_{i=1}^{N}$, historical buffer $\mathcal{G}_{\text{hist}}$, epochs $E=20$, $\kappa=2.5$
\Ensure Normal set $\mathcal{N}$, uncertain set $\mathcal{U}$, anomalous set $\mathcal{A}$
\State Initialize encoder $\phi_\theta$, decoder $\psi_\theta$ with latent dim $d = \lceil 0.1 \cdot \dim(\mathbf{g}) \rceil$
\For{epoch $= 1$ to $E$}
    \State $\mathcal{L} \gets \frac{1}{|\mathcal{G}_{\text{hist}}|} \sum_{\mathbf{g} \in \mathcal{G}_{\text{hist}}} \|\psi_\theta(\phi_\theta(\mathbf{g})) - \mathbf{g}\|^2$
    \State Update $\theta$ via Adam($\mathcal{L}$, lr=$10^{-3}$)
\EndFor
\State $\boldsymbol{\mu}_h \gets |\mathcal{G}_{\text{hist}}|^{-1} \sum_{\mathbf{g} \in \mathcal{G}_{\text{hist}}} \phi_\theta(\mathbf{g})$ \Comment{Latent centroid}
\For{$i = 1$ to $N$}
    \State $\ell_{\text{rec}} \gets \|\mathbf{g}_i - \psi_\theta(\phi_\theta(\mathbf{g}_i))\|^2$; \quad $\ell_{\text{lat}} \gets \|\phi_\theta(\mathbf{g}_i) - \boldsymbol{\mu}_h\|$
    \State $a_i \gets \lambda \cdot \ell_{\text{rec}}/\max_j \ell_{\text{rec}}^{(j)} + (1-\lambda) \cdot \ell_{\text{lat}}/\max_j \ell_{\text{lat}}^{(j)}$ \Comment{$\lambda=0.7$}
\EndFor
\State $\tau \gets \text{med}(\mathbf{a}) + \kappa \cdot 1.4826 \cdot \text{MAD}(\mathbf{a})$ \Comment{Adaptive threshold}
\State $\mathcal{N} \gets \{i : a_i < 0.7\tau\}$; $\mathcal{U} \gets \{i : 0.7\tau \le a_i < 1.5\tau\}$; $\mathcal{A} \gets \{i : a_i \ge 1.5\tau\}$
\State \Return $\mathcal{N}, \mathcal{U}, \mathcal{A}$
\end{algorithmic}
\end{algorithm}

\subsection{Committee Voting for Uncertain Gradients}

Gradients in the uncertain zone $\mathcal{U}$ are adjudicated by a committee of verified normal clients. Committee voting activates after a warm-up period of 5 rounds to allow reputation scores to stabilize.

\textbf{Diversity-maximizing selection.} A committee $\mathcal{C}$ of size $K=5$ is selected from $\mathcal{N}$ to maximize gradient-space coverage. The first member is the highest-reputation client: $c_1 = \arg\max_{i \in \mathcal{N}} \rho_i$. Subsequent members are chosen greedily to minimize maximum cosine similarity with existing members:
\begin{equation}
c_k = \arg\min_{i \in \mathcal{N} \setminus \mathcal{C}} \max_{j \in \mathcal{C}} \langle \mathbf{g}_i, \mathbf{g}_j \rangle / (\|\mathbf{g}_i\| \|\mathbf{g}_j\|)
\label{eq:committee}
\end{equation}
This diversity constraint reduces the risk of colluding attackers dominating the committee.

\textbf{Voting mechanism.} Each committee member $c$ casts a vote on uncertain gradient $\mathbf{g}_u$:
\begin{equation}
v_{c \to u} = \mathbf{1}\left[\cos(\mathbf{g}_u, \mathbf{g}_c) < \theta_v\right], \quad \theta_v = 0.3
\label{eq:vote}
\end{equation}
where $v=1$ indicates an anomalous vote. With self-exclusion (a client cannot vote on its own gradient), the decision rule is:
\begin{equation}
\text{label}(u) = \begin{cases}
\text{anomalous} & \text{if } \sum_{c \neq u} v_{c \to u} > 0.5 \cdot |\mathcal{C} \setminus \{u\}| \\
\text{normal} & \text{otherwise}
\end{cases}
\label{eq:decision}
\end{equation}

\begin{algorithm}[!ht]
\caption{Committee Selection and Voting}
\label{alg:committee}
\small
\begin{algorithmic}[1]
\Require Normal set $\mathcal{N}$, uncertain set $\mathcal{U}$, gradients $\{\mathbf{g}_i\}$, reputations $\{\rho_i\}$, $K=5$, $\theta_v=0.3$
\Ensure Updated sets $\mathcal{N}', \mathcal{A}'$
\State $\mathcal{C} \gets \{\arg\max_{i \in \mathcal{N}} \rho_i\}$ \Comment{Select highest-reputation client}
\While{$|\mathcal{C}| < K$}
    \State $c \gets \arg\min_{i \in \mathcal{N} \setminus \mathcal{C}} \max_{j \in \mathcal{C}} \cos(\mathbf{g}_i, \mathbf{g}_j)$
    \State $\mathcal{C} \gets \mathcal{C} \cup \{c\}$
\EndWhile
\For{each $u \in \mathcal{U}$}
    \State $v \gets \sum_{c \in \mathcal{C}, c \neq u} \mathbf{1}[\cos(\mathbf{g}_u, \mathbf{g}_c) < \theta_v]$
    \If{$v > 0.5 \cdot |\mathcal{C} \setminus \{u\}|$}
        \State $\mathcal{A}' \gets \mathcal{A}' \cup \{u\}$
    \Else
        \State $\mathcal{N}' \gets \mathcal{N}' \cup \{u\}$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{TLBO-Based Robust Aggregation}

The final stage aggregates verified gradients using Teaching-Learning-Based Optimization (TLBO)~\cite{Rao:2011}, a population-based metaheuristic that iteratively refines candidate solutions without algorithm-specific parameters.

Let $\mathcal{N}'$ denote the verified normal set after detection and committee voting. Each gradient $\mathbf{g}_i \in \mathcal{N}'$ is treated as a learner. The fitness function measures alignment with the reputation-weighted target:
\begin{equation}
f(\mathbf{g}) = \cos(\mathbf{g}, \bar{\mathbf{g}}), \quad \bar{\mathbf{g}} = \sum_{i \in \mathcal{N}'} \omega_i \mathbf{g}_i, \quad \omega_i = \rho_i / {\textstyle\sum_j \rho_j}
\label{eq:fitness}
\end{equation}
where $\rho_i$ is client $i$'s reputation score.

\textbf{Teacher phase.} Each learner moves toward the best-performing gradient (teacher) while moving away from the population mean:
\begin{equation}
\mathbf{g}_i' = \mathbf{g}_i + r \cdot (\mathbf{g}^* - T_F \cdot \bar{\boldsymbol{\mu}}), \quad r \sim \mathcal{U}(0,1), \; T_F \in \{1,2\}
\label{eq:teacher}
\end{equation}
where $\mathbf{g}^* = \arg\max f(\mathbf{g})$ and $\bar{\boldsymbol{\mu}}$ is the population mean.

\textbf{Learner phase.} Learners interact pairwise, moving toward superior peers:
\begin{equation}
\mathbf{g}_i' = \mathbf{g}_i + r \cdot \text{sign}(f(\mathbf{g}_i) - f(\mathbf{g}_j)) \cdot (\mathbf{g}_i - \mathbf{g}_j)
\label{eq:learner}
\end{equation}

Updates are accepted only if they improve fitness. After $T_{\text{TLBO}}=10$ iterations, the final target $\bar{\mathbf{g}}$ becomes the aggregated gradient for model update.

\begin{algorithm}[!ht]
\caption{TLBO-Based Gradient Aggregation}
\label{alg:tlbo}
\small
\begin{algorithmic}[1]
\Require Verified gradients $\{\mathbf{g}_i\}_{i \in \mathcal{N}'}$, reputations $\{\rho_i\}$, iterations $T=10$
\Ensure Aggregated gradient $\bar{\mathbf{g}}$
\State $\omega_i \gets \rho_i / \sum_{j} \rho_j$ for each $i \in \mathcal{N}'$ \Comment{Reputation weights}
\State $\bar{\mathbf{g}} \gets \sum_{i} \omega_i \mathbf{g}_i$ \Comment{Initial target}
\State $\mathcal{P} \gets \{\mathbf{g}_i\}_{i \in \mathcal{N}'}$ \Comment{Learner population}
\For{$t = 1$ to $T$}
    \State $f(\mathbf{g}) \gets \cos(\mathbf{g}, \bar{\mathbf{g}})$ for all $\mathbf{g} \in \mathcal{P}$ \Comment{Fitness}
    \State \textbf{// Teacher phase}
    \State $\mathbf{g}^* \gets \arg\max_{\mathbf{g} \in \mathcal{P}} f(\mathbf{g})$; \quad $\bar{\boldsymbol{\mu}} \gets |\mathcal{P}|^{-1} \sum_{\mathbf{g} \in \mathcal{P}} \mathbf{g}$
    \For{each $\mathbf{g}_i \in \mathcal{P}$}
        \State $T_F \sim \text{Uniform}(\{1, 2\})$; \quad $r \sim \mathcal{U}(0,1)$
        \State $\mathbf{g}_i' \gets \mathbf{g}_i + r \cdot (\mathbf{g}^* - T_F \cdot \bar{\boldsymbol{\mu}})$
        \If{$f(\mathbf{g}_i') > f(\mathbf{g}_i)$} $\mathbf{g}_i \gets \mathbf{g}_i'$ \EndIf
    \EndFor
    \State \textbf{// Learner phase}
    \For{each $\mathbf{g}_i \in \mathcal{P}$}
        \State Sample $\mathbf{g}_j \in \mathcal{P} \setminus \{\mathbf{g}_i\}$; \quad $r \sim \mathcal{U}(0,1)$
        \State $\mathbf{g}_i' \gets \mathbf{g}_i + r \cdot \text{sign}(f(\mathbf{g}_i) - f(\mathbf{g}_j)) \cdot (\mathbf{g}_i - \mathbf{g}_j)$
        \If{$f(\mathbf{g}_i') > f(\mathbf{g}_i)$} $\mathbf{g}_i \gets \mathbf{g}_i'$ \EndIf
    \EndFor
    \State $\bar{\mathbf{g}} \gets |\mathcal{P}|^{-1} \sum_{\mathbf{g} \in \mathcal{P}} \mathbf{g}$ \Comment{Update target}
\EndFor
\State \Return $\bar{\mathbf{g}}$
\end{algorithmic}
\end{algorithm}

\subsection{Reputation and Accountability Mechanisms}

\textbf{Reputation dynamics.} Each client maintains a reputation score $\rho_i \in [0.1, 2.0]$, initialized at 1.0. After each round, reputations update asymmetrically:
\begin{equation}
\rho_i^{(t+1)} = \begin{cases}
\min(\rho_i^{(t)} + 0.05 \cdot \xi_i, 2.0) & \text{if } i \in \mathcal{N}' \\
\max(0.7 \cdot \rho_i^{(t)}, 0.1) & \text{if } i \in \mathcal{A}'
\end{cases}
\label{eq:reputation}
\end{equation}
where $\xi_i = \max(0, (\cos(\mathbf{g}_i, \bar{\mathbf{g}}) + 1)/2)$ is the contribution score based on alignment with the aggregated gradient. This design creates strategic deterrence: reputations grow slowly but decay rapidly, making sustained attacks costly.

\textbf{Merkle-tree evidence.} For auditability, detection results $\{(i, a_i, \text{label}_i)\}$ at each round are hashed into a Merkle tree. The root hash $h^{(t)}$ is appended to an evidence chain $\mathcal{E} = \{h^{(1)}, \ldots, h^{(T)}\}$, enabling tamper-evident logging and $O(\log N)$ verification for dispute resolution.

\subsection{Complete FedACT Pipeline}

Algorithm~\ref{alg:fedact_complete} presents the complete FedACT pipeline integrating all components.

\begin{algorithm}[!ht]
\caption{Complete FedACT Framework}
\label{alg:fedact_complete}
\small
\begin{algorithmic}[1]
\Require Clients $\{1, \ldots, N\}$, global model $\mathbf{w}^{(0)}$, rounds $T$
\Ensure Final model $\mathbf{w}^{(T)}$, evidence chain $\mathcal{E}$
\State Initialize reputations $\rho_i \gets 1.0$ for all $i$
\State Initialize evidence chain $\mathcal{E} \gets \emptyset$
\For{round $t = 1$ to $T$}
    \State \textbf{// Client-side: Local training}
    \For{each client $i$ in parallel}
        \State Receive $\mathbf{w}^{(t-1)}$ from server
        \State Compute gradient $\mathbf{g}_i^{(t)} \gets \nabla F_i(\mathbf{w}^{(t-1)})$
        \State Send $\mathbf{g}_i^{(t)}$ to server
    \EndFor
    \State \textbf{// Server-side: FedACT defense}
    \State $\mathcal{N}, \mathcal{U}, \mathcal{A} \gets$ \textsc{AutoencoderDetection}$(\{\mathbf{g}_i^{(t)}\}, \mathcal{G}_{\text{hist}})$
    \If{$t > 5$ and $|\mathcal{U}| > 0$}
        \State $\mathcal{N}', \mathcal{A}' \gets$ \textsc{CommitteeVoting}$(\mathcal{N}, \mathcal{U}, \{\mathbf{g}_i\}, \{\rho_i\})$ \Comment{Alg.~\ref{alg:committee}}
    \Else
        \State $\mathcal{N}' \gets \mathcal{N} \cup \mathcal{U}$; \quad $\mathcal{A}' \gets \mathcal{A}$ \Comment{Warm-up: detector-only}
    \EndIf
    \State $\bar{\mathbf{g}} \gets$ \textsc{TLBOAggregation}$(\{\mathbf{g}_i\}_{i \in \mathcal{N}'}, \{\rho_i\})$
    \State \textbf{// Update model}
    \State $\mathbf{w}^{(t)} \gets \mathbf{w}^{(t-1)} - \eta \cdot \bar{\mathbf{g}}$
    \State \textbf{// Update reputations}
    \For{each $i \in \mathcal{N}'$}
        \State $c_i \gets \max\left(0, (\cos(\mathbf{g}_i^{(t)}, \bar{\mathbf{g}}) + 1)/2\right)$ \Comment{Alignment contribution}
        \State $\rho_i \gets \min(\rho_i + 0.05 \cdot c_i, 2.0)$
    \EndFor
    \For{each $i \in \mathcal{A}'$}
        \State $\rho_i \gets \max(\rho_i \times 0.7, 0.1)$
    \EndFor
    \State \textbf{// Record evidence}
    \State $h^{(t)} \gets$ \textsc{MerkleRoot}$(\{(i, a_i, \ell_i)\}_{i=1}^{N})$
    \State $\mathcal{E} \gets \mathcal{E} \cup \{h^{(t)}\}$
    \State Update: $\mathcal{G}_{\text{hist}} \gets \mathcal{G}_{\text{hist}} \cup \{\mathbf{g}_i^{(t)}\}_{i \in \mathcal{N}'}$
\EndFor
\State \Return $\mathbf{w}^{(T)}, \mathcal{E}$
\end{algorithmic}
\end{algorithm}

% (Removed: Computational Complexity / Theoretical Guarantees / Convergence Analysis to keep the manuscript strictly aligned with the implemented code and to avoid unverifiable claims.)


%==============================================================================
% SECTION 5: EXPERIMENTS
%==============================================================================
\section{Experiments}
\label{sec:experiments}

We evaluate FedACT on four research questions: (RQ1) detection effectiveness across attack types; (RQ2) comparison with baseline defenses; (RQ3) robustness under data heterogeneity; (RQ4) component contributions via ablation.

\subsection{Setup}

\textbf{Datasets.} We use two credit scoring datasets: UCI Credit Card Default~\cite{Yeh:2009} (30,000 samples, 23 features, 22.1\% default rate) and Xinwang Bank (50,000 samples, 35 features, 15.3\% default rate).

\textbf{Heterogeneity scenarios.} Data is partitioned across $N=10$ clients under four settings: IID (uniform random), label skew (Dirichlet $\beta=0.5$), feature skew (partial feature overlap), and quantity skew (power-law distribution).

\textbf{Model and training.} Three-layer MLP (Input$\to$128$\to$64$\to$1) with ReLU, Dropout(0.3), and Sigmoid output. Training uses binary cross-entropy, Adam ($\eta=10^{-3}$), batch size 64, $E=5$ local epochs, $T=100$ rounds.

\textbf{Attacks.} We evaluate 12 Byzantine attacks: basic (sign-flip, Gaussian, scaling), sophisticated (ALIE~\cite{Baruch:2019}, IPM~\cite{Xie:2020}, MinMax~\cite{Shejwalkar:2021}), and others (label-flip, backdoor~\cite{Bagdasaryan:2020}, free-riding, collusion). Default attacker ratio: $M=3$ of $N=10$ (30\%).

\textbf{Baselines.} FedAvg~\cite{McMahan:2017} (undefended), Median~\cite{Yin:2018}, TrimmedMean~\cite{Yin:2018}, Krum/Multi-Krum~\cite{Blanchard:2017}, Bulyan~\cite{ElMhamdi:2018}, RFA~\cite{Pillutla:2019}.

\textbf{Metrics.} Detection: Precision, Recall, F1. Model: Accuracy, AUC-ROC, Accuracy Preservation ($\text{Acc}_{\text{defended}}/\text{Acc}_{\text{clean}}$).

\subsection{Detection Effectiveness (RQ1)}

Table~\ref{tab:detection_results} reports FedACT's detection performance on UCI dataset under label skew with 30\% attackers. Basic perturbation attacks are detected with high precision and recall due to their pronounced deviation from the learned gradient manifold. Optimization-based attacks (ALIE, MinMax) are more challenging as they explicitly minimize statistical distinguishability, yet FedACT maintains competitive F1 scores through the combination of reconstruction-based and latent-deviation metrics.

\begin{table}[!ht]
\centering
\caption{FedACT detection performance (UCI, label skew, 30\% attackers)}
\label{tab:detection_results}
\small
\begin{tabular}{lccc}
\toprule
\textbf{Attack Type} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\midrule
\multicolumn{4}{l}{\textit{Basic Attacks}} \\
Sign-flipping & \textit{--} & \textit{--} & \textit{--} \\
Gaussian noise & \textit{--} & \textit{--} & \textit{--} \\
Scaling & \textit{--} & \textit{--} & \textit{--} \\
\midrule
\multicolumn{4}{l}{\textit{Sophisticated Attacks}} \\
Little & \textit{--} & \textit{--} & \textit{--} \\
ALIE & \textit{--} & \textit{--} & \textit{--} \\
IPM & \textit{--} & \textit{--} & \textit{--} \\
MinMax & \textit{--} & \textit{--} & \textit{--} \\
Trim attack & \textit{--} & \textit{--} & \textit{--} \\
\midrule
\multicolumn{4}{l}{\textit{Other Attacks}} \\
Label-flipping & \textit{--} & \textit{--} & \textit{--} \\
Backdoor & \textit{--} & \textit{--} & \textit{--} \\
Free-rider & \textit{--} & \textit{--} & \textit{--} \\
Collusion & \textit{--} & \textit{--} & \textit{--} \\
\midrule
\textbf{Average} & \textbf{\textit{--}} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
\bottomrule
\end{tabular}
\end{table}

FedACT achieves strong detection performance across attack families, with simple perturbation attacks being easier to detect than optimization-based attacks that explicitly mimic benign statistics.

\subsection{Comparison with Baselines (RQ2)}

Table~\ref{tab:baseline_comparison} compares model accuracy under various attacks (30\% attackers, label skew).

\begin{table*}[!ht]
\centering
\caption{Model accuracy comparison across defense methods (UCI, label skew, 30\% attackers)}
\label{tab:baseline_comparison}
\small
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\textbf{Attack} & \textbf{None} & \textbf{Median} & \textbf{TrimMean} & \textbf{Krum} & \textbf{Multi-Krum} & \textbf{Bulyan} & \textbf{RFA} & \textbf{FedACT} \\
\midrule
No attack & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\midrule
Sign-flip & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
Gaussian & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
Scaling & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
ALIE & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
IPM & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
MinMax & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
Label-flip & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
Backdoor & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
\midrule
\textbf{Average} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
\textbf{Preserve \%} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textit{--} & \textbf{\textit{--}} \\
\bottomrule
\end{tabular}
}
\end{table*}

FedACT maintains high accuracy by combining explicit anomaly detection with robust aggregation. Robust statistics-based defenses offer partial protection but may be evaded by carefully crafted attacks. Distance-based methods can be stressed by heterogeneity, while FedACT's detection and uncertainty resolution mitigate this.

\subsection{Robustness Under Heterogeneity (RQ3)}

Table~\ref{tab:heterogeneity_results} evaluates FedACT under different heterogeneity types (MinMax attack, 30\% attackers).

\begin{table}[!ht]
\centering
\caption{FedACT performance under heterogeneity scenarios (MinMax attack)}
\label{tab:heterogeneity_results}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Heterogeneity} & \textbf{Precision} & \textbf{Recall} & \textbf{Accuracy} & \textbf{AUC} \\
\midrule
IID & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
Label skew & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
Feature skew & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
Quantity skew & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\midrule
\textbf{Average} & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\bottomrule
\end{tabular}
\end{table}

FedACT maintains stable performance across heterogeneity scenarios. Feature skew presents the greatest challenge due to structural gradient differences; the uncertainty zone mitigates false positives from legitimate heterogeneity. Quantity skew is addressed through reputation-weighted aggregation.

Table~\ref{tab:attacker_ratio} shows graceful degradation as attacker ratio increases from 10\% to 45\%. The three-stage pipeline maintains detection effectiveness near the honest-majority boundary.

\begin{table}[!ht]
\centering
\caption{Performance under varying attacker ratios (MinMax attack, label skew)}
\label{tab:attacker_ratio}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Attacker \%} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Accuracy} \\
\midrule
10\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
20\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
30\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
35\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
40\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
45\% & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\bottomrule
\end{tabular}
\end{table}
FedACT degrades gracefully as attacker ratio increases by combining conservative filtering, uncertainty handling, and robust aggregation over verified updates.

\subsection{Ablation Study (RQ4)}

Table~\ref{tab:ablation} isolates component contributions under MinMax attack (30\% attackers, label skew). Removing the autoencoder significantly degrades detection of clearly anomalous updates. Removing committee voting increases false positives in borderline cases where heterogeneity resembles adversarial behavior.

Table~\ref{tab:aggregation_comparison} compares aggregation algorithms without defense components. Metaheuristic methods (FedTLBO, FedGWO, FedPSO) outperform standard FL algorithms (FedAvg, FedProx) but remain vulnerable to sophisticated attacks without explicit detection.

\begin{table}[!ht]
\centering
\caption{Ablation study: FedACT component contributions}
\label{tab:ablation}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{Precision} & \textbf{Recall} & \textbf{Accuracy} & \textbf{F1} \\
\midrule
\multicolumn{5}{l}{\textit{Part 1: Component Ablation}} \\
\midrule
FedACT\_Full & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
w/o\_Autoencoder & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
w/o\_Committee & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\bottomrule
\end{tabular}
\end{table}

Removing the autoencoder impacts filtering of clearly anomalous updates; removing committee voting affects borderline decisions where heterogeneity resembles adversarial behavior.

Table~\ref{tab:aggregation_comparison} presents the aggregation algorithm comparison results (Only\_Agg, no defense components, three representative attacks).

\begin{table}[!ht]
\centering
\caption{Aggregation algorithm comparison without defense components (Only\_Agg)}
\label{tab:aggregation_comparison}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{Sign-flip} & \textbf{ALIE} & \textbf{MinMax} & \textbf{Average} \\
\midrule
FedAvg & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
FedProx & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
SCAFFOLD & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
MOON & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\midrule
FedPSO & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
FedGWO & \textit{--} & \textit{--} & \textit{--} & \textit{--} \\
\textbf{FedTLBO} & \textbf{\textit{--}} & \textbf{\textit{--}} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
\bottomrule
\end{tabular}
\end{table}

Metaheuristic aggregation improves robustness but without detection remains susceptible to crafted attacks. FedACT combines both so that optimization operates on verified updates.

\subsection{Sensitivity Analysis}

Table~\ref{tab:sensitivity} shows FedACT is robust to hyperparameter choices. The default configuration ($c_{\text{lower}}=0.7$, $c_{\text{upper}}=1.5$, $K=5$, $T_{\text{TLBO}}=10$) balances detection sensitivity with false positive avoidance across tested ranges.

\begin{table}[!ht]
\centering
\caption{Parameter sensitivity (MinMax attack, 30\% attackers)}
\label{tab:sensitivity}
\small
\begin{tabular}{lccc}
\toprule
\textbf{Parameter} & \textbf{Values} & \textbf{Accuracy} & \textbf{Detection F1} \\
\midrule
\multirow{3}{*}{$c_{lower}$} & 0.5 & \textit{--} & \textit{--} \\
& \textbf{0.7} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
& 0.9 & \textit{--} & \textit{--} \\
\midrule
\multirow{3}{*}{$c_{upper}$} & 1.2 & \textit{--} & \textit{--} \\
& \textbf{1.5} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
& 1.8 & \textit{--} & \textit{--} \\
\midrule
\multirow{3}{*}{Committee size $K$} & 3 & \textit{--} & \textit{--} \\
& \textbf{5} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
& 7 & \textit{--} & \textit{--} \\
\midrule
\multirow{3}{*}{TLBO iterations} & 5 & \textit{--} & \textit{--} \\
& \textbf{10} & \textbf{\textit{--}} & \textbf{\textit{--}} \\
& 20 & \textit{--} & \textit{--} \\
\bottomrule
\end{tabular}
\end{table}

FedACT is relatively robust to parameter choices. Default values ($c_{lower}=0.7$, $c_{upper}=1.5$, $K=5$, $T_{TLBO}=10$) provide good balance between detection sensitivity and false positive avoidance.
%==============================================================================
% SECTION 7: CONCLUSION
%==============================================================================
\section{Conclusion}
\label{sec:conclusion}

This paper proposed FedACT, a Byzantine-resilient federated learning framework that addresses the heterogeneity-tolerance gap in cross-silo credit scoring. By integrating autoencoder-based anomaly detection, diversity-constrained committee voting, and TLBO-based robust aggregation with reputation-driven incentives, FedACT achieves effective attack detection without the IID assumptions that limit existing defenses. Experimental evaluation across twelve attack types and four heterogeneity scenarios validates the contribution of each component.

From a governance perspective, FedACT separates detection, adjudication, and aggregation into auditable stages with Merkle-tree evidence recording, operationalizing accountability requirements for regulated financial consortia.

Future work includes adversarially robust training against autoencoder-aware evasion, continual adaptation for concept drift, communication-efficient variants, extension to vertical FL, and formal convergence analysis.


%==============================================================================
% ACKNOWLEDGMENTS
%==============================================================================
\section*{Acknowledgments}

This work was supported by the National Natural Science Foundation of China (Grant No. 72171073) and the Research Fund of Hunan University. The authors thank the anonymous reviewers for their constructive feedback.


%==============================================================================
% REFERENCES
%==============================================================================
\bibliographystyle{cas-model2-names}
\bibliography{FedACT-refs}

\end{document}
