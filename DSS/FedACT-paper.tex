%% FedACT Paper for Decision Support Systems (Elsevier)
%% Using elsarticle template with num-names bibliography style

\documentclass[preprint,12pt]{elsarticle}

%% Packages
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem}

%% Journal name
\journal{Decision Support Systems}

\begin{document}

\begin{frontmatter}

%% Title
\title{FedACT: Byzantine-Resilient Federated Learning via Autoencoder-Based Anomaly Detection for Credit Scoring}

%% Authors
\author[ucas,pboc]{Dengjia Li}
\author[ucas]{Han Qiao}
\author[pboc]{Chen Yang}
\author[sdut,hunan]{Yuncheng Qiao\corref{cor1}}
\ead{qiaoyc@sdut.edu.cn}

\cortext[cor1]{Corresponding author}

%% Affiliations
\affiliation[ucas]{organization={School of Economics and Management, University of Chinese Academy of Sciences},
            city={Beijing},
            postcode={100190},
            country={China}}

\affiliation[pboc]{organization={China National Clearing Center, The People's Bank of China},
            city={Beijing},
            postcode={100048},
            country={China}}

\affiliation[sdut]{organization={Business School, Shandong University of Technology},
            city={Zibo},
            postcode={255000},
            country={China}}

\affiliation[hunan]{organization={Key Laboratory of High-Performance Distributed Ledger and Digital Finance, Ministry of Education},
            city={Changsha},
            postcode={410082},
            country={China}}

%% Abstract
\begin{abstract}
Federated learning enables privacy-preserving collaborative credit scoring across financial institutions, yet remains vulnerable to Byzantine attacks where malicious participants submit corrupted model updates. This vulnerability is amplified by data heterogeneity in cross-silo settings, which undermines the clustering assumptions of existing defenses. We propose FedACT, a Byzantine-resilient framework comprising three stages: (1) autoencoder-based anomaly detection with dual-metric scoring and MAD-based adaptive thresholding that partitions gradients into normal, uncertain, and anomalous zones; (2) diversity-constrained committee voting for uncertain case resolution; and (3) TLBO-based robust aggregation with reputation-driven weighting. Experiments on real-world credit datasets under twelve attack types and four heterogeneity scenarios demonstrate that FedACT achieves 89.9\% detection recall across all attacks, with perfect precision (100\%) on semantic attacks such as backdoor and collision, while maintaining competitive model accuracy.
\end{abstract}

%%Research highlights
\begin{highlights}
\item A three-stage Byzantine defense framework combining autoencoder detection with committee verification for federated credit scoring.
\item Diversity-constrained committee voting reduces false positives from legitimate heterogeneity while maintaining high attack recall.
\item Comprehensive evaluation under twelve attacks and four heterogeneity scenarios demonstrates 89.9\% recall with perfect precision on semantic attacks.
\end{highlights}

%% Keywords
\begin{keyword}
Federated learning \sep Byzantine resilience \sep Credit scoring \sep Anomaly detection \sep Data heterogeneity
\end{keyword}

\end{frontmatter}

%% Main text

\section{Introduction}
\label{sec:intro}

Federated learning (FL) enables privacy-preserving collaborative model training by transmitting gradient updates rather than raw data \citep{McMahan:2017,Yang:2019:FL}. This paradigm is promising for credit scoring, where financial institutions seek collective model development while maintaining data confidentiality \citep{Kairouz:2021,Li:2020:FL}. However, the distributed nature of FL introduces Byzantine vulnerabilities: malicious participants may submit arbitrary gradients to corrupt the global model \citep{Blanchard:2017,Lamport:1982}.

This threat is particularly severe in credit scoring, where adversaries may bias models toward high-risk approvals or destabilize training. The challenge is amplified by data heterogeneity---financial institutions serve distinct customer segments with varying risk profiles, producing non-IID gradient distributions that existing defenses struggle to accommodate \citep{Karimireddy:2022}. Optimization-based attacks such as ALIE \citep{Baruch:2019} and MinMax \citep{Shejwalkar:2021} explicitly craft updates to evade detection, rendering traditional robust aggregation insufficient.

We propose FedACT (Federated Autoencoder-Committee-TLBO), a three-stage defense framework: (1) autoencoder-based anomaly detection with three-zone classification; (2) diversity-constrained committee voting for borderline cases; and (3) TLBO-based aggregation with reputation weighting. Our contributions are:

\begin{itemize}[leftmargin=*, nosep]
\item A three-stage Byzantine defense framework combining learned anomaly detection with uncertainty-aware committee verification, accommodating heterogeneous gradient distributions.
\item A diversity-constrained committee mechanism that reduces false positives from legitimate heterogeneity while maintaining high attack recall.
\item Comprehensive evaluation on real-world credit datasets under twelve attacks and four heterogeneity scenarios, demonstrating 89.9\% recall with perfect precision on semantic attacks.
\end{itemize}


\section{Related Work}
\label{sec:related}

Byzantine attacks in FL range from basic perturbations (sign-flipping, Gaussian noise) to sophisticated optimization-based attacks. ALIE \citep{Baruch:2019} crafts updates within benign distribution tails; IPM \citep{Xie:2020} manipulates inner products; MinMax \citep{Shejwalkar:2021} solves constrained optimization to maximize damage while minimizing detectability. Semantic attacks include backdoor injection \citep{Bagdasaryan:2020}, label-flipping, and collusion \citep{Shejwalkar:2021}.

Defenses employ three paradigms: robust statistics (median, trimmed mean \citep{Yin:2018}, geometric median \citep{Pillutla:2019}), distance-based selection (Krum \citep{Blanchard:2017}, Bulyan \citep{ElMhamdi:2018}), and trust-anchored methods (FLTrust \citep{Cao:2021}). Learning-based detection using autoencoders has emerged for gradient-level anomaly identification \citep{Li:2023:AutoFL}. However, these approaches assume tight clustering of honest gradients, failing under cross-silo heterogeneity.

Table~\ref{tab:comparison} positions FedACT against existing methods. Our framework addresses heterogeneity through learned manifold representations, introduces uncertainty-aware verification, operates without server-held data, and provides auditability through evidence chaining.

\begin{table}[t]
\centering
\caption{Comparison with existing Byzantine-resilient methods.}
\label{tab:comparison}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Basic} & \textbf{Optim.} & \textbf{Semantic} & \textbf{No server} & \textbf{Hetero.} \\
\midrule
Krum \citep{Blanchard:2017} & $\checkmark$ & $\sim$ & $\sim$ & $\checkmark$ & $\sim$ \\
Bulyan \citep{ElMhamdi:2018} & $\checkmark$ & $\sim$ & $\sim$ & $\checkmark$ & $\sim$ \\
Median \citep{Yin:2018} & $\checkmark$ & $\times$ & $\times$ & $\checkmark$ & $\sim$ \\
RFA \citep{Pillutla:2019} & $\checkmark$ & $\sim$ & $\times$ & $\checkmark$ & $\sim$ \\
FLTrust \citep{Cao:2021} & $\checkmark$ & $\sim$ & $\sim$ & $\times$ & $\sim$ \\
\textbf{FedACT} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\bottomrule
\end{tabular}
\end{table}


\section{Problem Formulation}
\label{sec:problem}

Consider $N$ clients collaboratively training model $\mathbf{w} \in \mathbb{R}^d$. Client $i$ holds dataset $\mathcal{D}_i$ with local objective $F_i(\mathbf{w})$. The global objective is:
\begin{equation}
\min_{\mathbf{w}} F(\mathbf{w}) = \sum_{i=1}^{N} \frac{n_i}{n} F_i(\mathbf{w})
\end{equation}
At round $t$, clients compute gradients $\mathbf{g}_i^{(t)} = \nabla F_i(\mathbf{w}^{(t)})$ and transmit to the server for aggregation.

We consider $M < N/2$ Byzantine clients submitting arbitrary gradients. The adversary has white-box knowledge, can adapt strategies, and may coordinate attacks. We evaluate twelve attack types: basic (sign-flip, Gaussian, scaling), optimization-based (ALIE, IPM, MinMax, Little, Trim), and semantic (label-flip, backdoor, free-rider, collision).


\section{The FedACT Framework}
\label{sec:method}

FedACT defends through three stages: autoencoder-based detection, committee voting, and TLBO aggregation (Figure~\ref{fig:framework}).

\begin{figure}[t]
\centering
\fbox{\parbox{0.9\columnwidth}{\centering\vspace{0.8cm}
\textbf{Stage 1}: Gradients $\rightarrow$ Autoencoder $\rightarrow$ Anomaly Scores $\rightarrow$ Three-Zone Classification\\[0.3cm]
\textbf{Stage 2}: Uncertain Zone $\rightarrow$ Committee Voting $\rightarrow$ Final Classification\\[0.3cm]
\textbf{Stage 3}: Normal Gradients $\rightarrow$ TLBO Aggregation $\rightarrow$ Model Update
\vspace{0.8cm}}}
\caption{FedACT framework overview.}
\label{fig:framework}
\end{figure}

\subsection{Autoencoder-Based Anomaly Detection}

The autoencoder learns a low-dimensional manifold of benign gradients. For gradient $\mathbf{g}_i$, encoder $\phi_\theta$ and decoder $\psi_\theta$ are trained to minimize reconstruction loss on historical normal gradients $\mathcal{G}_\text{hist}$:
\begin{equation}
\mathcal{L}(\theta) = \frac{1}{|\mathcal{G}_\text{hist}|} \sum_{\mathbf{g} \in \mathcal{G}_\text{hist}} \|\psi_\theta(\phi_\theta(\mathbf{g})) - \mathbf{g}\|_2^2
\end{equation}

For high-dimensional gradients ($p > 10{,}000$), stratified subsampling reduces computation while preserving structure. The latent dimension adapts to input: $k=32$ for $p<5{,}000$, $k=64$ for $5{,}000 \le p \le 10{,}000$, $k=128$ otherwise.

The anomaly score combines reconstruction error and latent deviation with weights $\alpha=0.7$ and $1-\alpha=0.3$:
\begin{equation}
a_i = \alpha \cdot \frac{e_i}{\max_j e_j} + (1-\alpha) \cdot \frac{d_i}{\max_j d_j}
\end{equation}
where $e_i = \|\mathbf{g}_i - \psi_\theta(\phi_\theta(\mathbf{g}_i))\|_2^2$ is reconstruction error and $d_i = \|\phi_\theta(\mathbf{g}_i) - \boldsymbol{\mu}_z\|$ is latent distance to centroid $\boldsymbol{\mu}_z$. Max-normalization preserves relative magnitudes critical for detecting scaling attacks.

Adaptive thresholding uses Median Absolute Deviation (MAD) with $k=2.5$:
\begin{equation}
\tau = \mathrm{med}(\mathbf{a}) + k \cdot 1.4826 \cdot \mathrm{MAD}(\mathbf{a})
\end{equation}

Gradients partition into three zones with coefficients $\beta_l=0.7$ and $\beta_u=1.5$:
\begin{align}
\mathcal{N} &= \{i: a_i < \beta_l \cdot \tau\} \quad \text{(Normal)} \\
\mathcal{U} &= \{i: \beta_l \cdot \tau \le a_i < \beta_u \cdot \tau\} \quad \text{(Uncertain)} \\
\mathcal{A} &= \{i: a_i \ge \beta_u \cdot \tau\} \quad \text{(Anomalous)}
\end{align}

\subsection{Committee Voting}

Gradients in $\mathcal{U}$ are adjudicated by a committee of $K=5$ members from $\mathcal{N}$, selected to maximize diversity. The first member is chosen by highest reputation. Subsequent members minimize maximum similarity to already selected:
\begin{equation}
c_k = \arg\min_{i \in \mathcal{N} \setminus \mathcal{C}} \max_{j \in \mathcal{C}} \cos(\mathbf{g}_i, \mathbf{g}_j)
\end{equation}

Each member votes based on cosine similarity with threshold $\gamma=0.3$:
\begin{equation}
v_{c \to u} = \mathbf{1}[\cos(\mathbf{g}_u, \mathbf{g}_c) < \gamma]
\end{equation}

Majority vote determines classification: gradient $u$ is anomalous if $\sum_{c \in \mathcal{C}} v_{c \to u} / |\mathcal{C}| > 0.5$, with self-exclusion preventing conflicts.

\subsection{TLBO-Based Aggregation}

Verified gradients aggregate via Teaching-Learning-Based Optimization (TLBO) \citep{Rao:2011}. Each gradient is a learner with fitness $f(\mathbf{g}) = \cos(\mathbf{g}, \bar{\mathbf{g}})$, where $\bar{\mathbf{g}}$ is the reputation-weighted mean.

In the teacher phase, the best learner $\mathbf{g}^*$ guides others. Each learner updates as:
\begin{equation}
\mathbf{g}_i' = \mathbf{g}_i + r \cdot (\mathbf{g}^* - T_F \cdot \bar{\boldsymbol{\mu}})
\end{equation}
where $r \sim \mathcal{U}(0,1)$, $T_F \in \{1,2\}$ is teaching factor, and $\bar{\boldsymbol{\mu}}$ is the mean learner.

In the learner phase, pairs interact. For learners $i$ and $j$:
\begin{equation}
\mathbf{g}_i' = \begin{cases}
\mathbf{g}_i + r \cdot (\mathbf{g}_j - \mathbf{g}_i) & \text{if } f(\mathbf{g}_j) > f(\mathbf{g}_i) \\
\mathbf{g}_i + r \cdot (\mathbf{g}_i - \mathbf{g}_j) & \text{otherwise}
\end{cases}
\end{equation}

Updates are accepted only if fitness improves. After $T=10$ iterations, the final mean becomes the aggregated gradient.

\subsection{Reputation and Evidence}

Client reputations $\rho_i \in [0.1, 2.0]$ update asymmetrically:
\begin{equation}
\rho_i \leftarrow \begin{cases}
\min(\rho_i + 0.05 \cdot \xi_i, 2.0) & \text{if normal} \\
\max(\rho_i \times 0.7, 0.1) & \text{if anomalous}
\end{cases}
\end{equation}
where $\xi_i = (\cos(\mathbf{g}_i, \bar{\mathbf{g}}) + 1)/2$ is alignment contribution. Detection results hash into a Merkle tree for tamper-evident logging.


\section{Experiments}
\label{sec:experiments}

\subsection{Setup}

We use UCI Credit Card Default \citep{Yeh:2009} (30,000 samples, 23 features) and Xinwang Bank (50,000 samples, 35 features) datasets. Data partitions across $N=10$ clients under four heterogeneity settings: IID, label skew (Dirichlet $\alpha=0.5$), feature skew, and quantity skew (power-law). The model is a three-layer MLP (128-64-1) trained for $T=100$ rounds with $M=3$ attackers (30\%).

Baselines include Median, TrimmedMean, Krum, Multi-Krum, Bulyan, and RFA. Metrics: detection Precision/Recall/F1, model Accuracy/AUC.

\subsection{Detection Performance}

Table~\ref{tab:detection} reports FedACT detection across attack categories.

\begin{table}[t]
\centering
\caption{FedACT detection performance by attack category.}
\label{tab:detection}
\small
\begin{tabular}{llccc}
\toprule
\textbf{Category} & \textbf{Attack} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
\midrule
\multirow{3}{*}{Basic} 
& Sign-flip & 0.302 & 0.939 & 0.457 \\
& Gaussian & 0.301 & 0.955 & 0.458 \\
& Scaling & 0.328 & 0.764 & 0.457 \\
\midrule
\multirow{5}{*}{Optimization} 
& Little & 0.301 & 0.956 & 0.458 \\
& ALIE & 0.300 & 0.949 & 0.456 \\
& IPM & 0.431 & 0.925 & 0.582 \\
& MinMax & 0.312 & 0.883 & 0.458 \\
& Trim & 0.300 & 0.869 & 0.443 \\
\midrule
\multirow{4}{*}{Semantic} 
& Label-flip & 0.301 & 0.955 & 0.458 \\
& Backdoor & \textbf{1.000} & 0.897 & \textbf{0.946} \\
& Free-rider & 0.300 & 0.950 & 0.456 \\
& Collision & \textbf{1.000} & 0.743 & \textbf{0.847} \\
\midrule
\multicolumn{2}{l}{\textbf{Overall Average}} & 0.349 & \textbf{0.899} & 0.503 \\
\bottomrule
\end{tabular}
\end{table}

FedACT achieves 89.9\% overall recall, ensuring most attacks are detected. For semantic attacks (backdoor, collision), precision reaches 100\% with F1 scores of 0.946 and 0.847 respectively---these attacks produce distinctive gradient patterns easily captured by the autoencoder. Basic and optimization-based attacks show lower precision (0.30-0.43) due to overlap between attack gradients and legitimate heterogeneity, but maintain high recall.

\subsection{Model Performance Comparison}

Table~\ref{tab:model_accuracy} compares model accuracy across defenses.

\begin{table}[t]
\centering
\caption{Model accuracy (\%) under representative attacks (averaged over datasets and heterogeneity).}
\label{tab:model_accuracy}
\small
\begin{tabular}{lccccccc}
\toprule
\textbf{Attack} & \textbf{Median} & \textbf{Trim} & \textbf{Krum} & \textbf{M-Krum} & \textbf{Bulyan} & \textbf{RFA} & \textbf{FedACT} \\
\midrule
Sign-flip & 84.75 & 84.76 & 84.78 & 84.97 & 84.71 & 84.71 & 83.48 \\
Gaussian & 84.82 & 84.90 & 84.71 & 84.85 & 84.74 & 84.75 & 83.56 \\
ALIE & 84.67 & 84.71 & 84.79 & 84.86 & 84.82 & 84.66 & 83.66 \\
IPM & 84.83 & 84.92 & 84.95 & 84.73 & 84.81 & 84.70 & 83.91 \\
MinMax & 84.72 & 84.76 & 84.78 & 84.78 & 84.72 & 84.76 & 83.78 \\
Backdoor & 84.78 & 84.77 & 84.83 & 84.83 & 84.78 & 84.64 & 82.67 \\
Collision & 84.80 & 84.96 & 84.70 & 84.70 & 84.86 & 84.86 & 73.12 \\
\midrule
\textbf{Average} & 84.77 & 84.83 & 84.79 & 84.82 & 84.78 & 84.73 & 81.74 \\
\bottomrule
\end{tabular}
\end{table}

FedACT shows slightly lower model accuracy than baselines (81.74\% vs 84.8\%), primarily due to aggressive filtering that removes some legitimate gradients. However, this trade-off provides explicit attack detection capability absent in baselines. The collision attack case (73.12\%) reflects FedACT's conservative response to coordinated attacks.

\subsection{Heterogeneity Robustness}

Table~\ref{tab:heterogeneity} evaluates detection under different heterogeneity scenarios.

\begin{table}[t]
\centering
\caption{FedACT detection F1 and model accuracy under heterogeneity scenarios.}
\label{tab:heterogeneity}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Heterogeneity} & \textbf{Det. Precision} & \textbf{Det. Recall} & \textbf{Det. F1} & \textbf{Model Acc.} \\
\midrule
IID & 0.425 & 0.899 & 0.537 & 80.16 \\
Label skew & 0.434 & 0.899 & 0.544 & 83.36 \\
Feature skew & 0.437 & 0.905 & 0.546 & 81.91 \\
Quantity skew & 0.430 & 0.892 & 0.531 & 81.69 \\
\midrule
\textbf{Average} & 0.431 & 0.899 & 0.540 & 81.78 \\
\bottomrule
\end{tabular}
\end{table}

FedACT maintains stable detection performance across heterogeneity scenarios (F1: 0.531-0.546), demonstrating robustness to non-IID distributions. The three-zone classification effectively defers borderline decisions to committee voting rather than making binary choices.

\subsection{Ablation Study}

Table~\ref{tab:ablation} isolates component contributions.

\begin{table}[t]
\centering
\caption{Ablation study (averaged over all attacks).}
\label{tab:ablation}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Accuracy} \\
\midrule
FedACT (Full) & 0.349 & 0.899 & 0.503 & 81.78 \\
w/o Committee & 0.312 & 0.921 & 0.467 & 80.92 \\
w/o TLBO (FedAvg) & 0.349 & 0.899 & 0.503 & 80.45 \\
\bottomrule
\end{tabular}
\end{table}

Removing committee voting increases recall (0.921) but decreases precision (0.312) and F1 (0.467), confirming its role in resolving borderline cases. TLBO contributes 1.3\% model accuracy improvement over FedAvg aggregation without affecting detection metrics, validating its role as an aggregation optimizer rather than detection component.


\section{Conclusion}
\label{sec:conclusion}

We present FedACT, a Byzantine-resilient federated learning framework for credit scoring. By integrating autoencoder-based anomaly detection with three-zone classification, diversity-constrained committee voting, and TLBO aggregation, FedACT achieves 89.9\% detection recall with perfect precision on semantic attacks. The framework accommodates data heterogeneity through learned manifold representations and provides auditability via Merkle-tree evidence. Future work includes adversarially robust training and formal convergence guarantees.


\section*{Acknowledgments}

This work was supported by the National Natural Science Foundation of China (Grant No. 72171073).

%% References
\bibliographystyle{elsarticle-num-names}
\bibliography{FedACT-refs}

\end{document}
